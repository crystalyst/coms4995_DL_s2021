{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceSuperResolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYLBK52udWC5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4z495AbSR1"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/gdrive/MyDrive/Face-Super-Resolution')\n",
        "import os\n",
        "\n",
        "from dlib_alignment import dlib_detect_face, face_recover\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from models.SRGAN_model import SRGANModel\n",
        "import numpy as np\n",
        "import argparse\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc9FMNxg2lFN",
        "outputId": "95a8a17d-975a-4c00-ce6c-d98f88a16c10"
      },
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 \"shape_predictor_68_face_landmarks.dat.bz2\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-09 13:36:53--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  63.0MB/s    in 1.0s    \n",
            "\n",
            "2021-08-09 13:36:54 (63.0 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZCuWwykb1KH"
      },
      "source": [
        "_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                                      std=[0.5, 0.5, 0.5])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqEwSIWfb1MQ"
      },
      "source": [
        "def get_FaceSR_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--gpu_ids', type=str, default=None)\n",
        "    parser.add_argument('--batch_size', type=int, default=32)\n",
        "    parser.add_argument('--lr_G', type=float, default=1e-4)\n",
        "    parser.add_argument('--weight_decay_G', type=float, default=0)\n",
        "    parser.add_argument('--beta1_G', type=float, default=0.9)\n",
        "    parser.add_argument('--beta2_G', type=float, default=0.99)\n",
        "    parser.add_argument('--lr_D', type=float, default=1e-4)\n",
        "    parser.add_argument('--weight_decay_D', type=float, default=0)\n",
        "    parser.add_argument('--beta1_D', type=float, default=0.9)\n",
        "    parser.add_argument('--beta2_D', type=float, default=0.99)\n",
        "    parser.add_argument('--lr_scheme', type=str, default='MultiStepLR')\n",
        "    parser.add_argument('--niter', type=int, default=100000)\n",
        "    parser.add_argument('--warmup_iter', type=int, default=-1)\n",
        "    parser.add_argument('--lr_steps', type=list, default=[50000])\n",
        "    parser.add_argument('--lr_gamma', type=float, default=0.5)\n",
        "    parser.add_argument('--pixel_criterion', type=str, default='l1')\n",
        "    parser.add_argument('--pixel_weight', type=float, default=1e-2)\n",
        "    parser.add_argument('--feature_criterion', type=str, default='l1')\n",
        "    parser.add_argument('--feature_weight', type=float, default=1)\n",
        "    parser.add_argument('--gan_type', type=str, default='ragan')\n",
        "    parser.add_argument('--gan_weight', type=float, default=5e-3)\n",
        "    parser.add_argument('--D_update_ratio', type=int, default=1)\n",
        "    parser.add_argument('--D_init_iters', type=int, default=0)\n",
        "\n",
        "    parser.add_argument('--print_freq', type=int, default=100)\n",
        "    parser.add_argument('--val_freq', type=int, default=1000)\n",
        "    parser.add_argument('--save_freq', type=int, default=10000)\n",
        "    parser.add_argument('--crop_size', type=float, default=0.85)\n",
        "    parser.add_argument('--lr_size', type=int, default=128)\n",
        "    parser.add_argument('--hr_size', type=int, default=512)\n",
        "\n",
        "    # network G\n",
        "    parser.add_argument('--which_model_G', type=str, default='RRDBNet')\n",
        "    parser.add_argument('--G_in_nc', type=int, default=3)\n",
        "    parser.add_argument('--out_nc', type=int, default=3)\n",
        "    parser.add_argument('--G_nf', type=int, default=64)\n",
        "    parser.add_argument('--nb', type=int, default=16)\n",
        "\n",
        "    # network D\n",
        "    parser.add_argument('--which_model_D', type=str, default='discriminator_vgg_128')\n",
        "    parser.add_argument('--D_in_nc', type=int, default=3)\n",
        "    parser.add_argument('--D_nf', type=int, default=64)\n",
        "\n",
        "    # data dir\n",
        "    parser.add_argument('--pretrain_model_G', type=str, default='90000_G.pth')\n",
        "    parser.add_argument('--pretrain_model_D', type=str, default=None)\n",
        "\n",
        "    #args = parser.parse_args()\n",
        "    args = parser.parse_args(args=[])\n",
        "    \n",
        "    return args\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV7TDF_hb1OY",
        "outputId": "8a8bc0d3-b410-4861-b06f-f56f4e586e50"
      },
      "source": [
        "sr_model = SRGANModel(get_FaceSR_opt(), is_train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network G structure: DataParallel - RRDBNet, with parameters: 11,662,019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZyIwBunb1Qs"
      },
      "source": [
        "sr_model.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQPQ2cPzb7p7"
      },
      "source": [
        "def sr_forward(img, padding=0.5, moving=0.1):\n",
        "    #img_aligned, M = dlib_detect_face(img, padding=padding, image_size=(128, 128), moving=moving)\n",
        "    input_img = torch.unsqueeze(_transform(Image.fromarray(img_aligned)), 0)\n",
        "    sr_model.var_L = input_img.to(sr_model.device)\n",
        "    sr_model.test()\n",
        "    output_img = sr_model.fake_H.squeeze(0).cpu().numpy()\n",
        "    output_img = np.clip((np.transpose(output_img, (1, 2, 0)) / 2.0 + 0.5) * 255.0, 0, 255).astype(np.uint8)\n",
        "    #rec_img = face_recover(output_img, M * 4, img)\n",
        "    return output_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6HEO0yVb7sJ"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "img_pathes = glob('/gdrive/MyDrive/Kinship Recognition Starter_original/train/train-faces/' + \"*/*/*.jpg\")\n",
        "\n",
        "for img_path in img_pathes:\n",
        "  img = utils.read_cv2_img(img_path)\n",
        "  output_img = sr_forward(img)\n",
        "\n",
        "  output_name = img_path.replace('/gdrive/MyDrive/Kinship Recognition Starter_original/','')\n",
        "  os.makedirs(os.path.dirname(output_name), exist_ok=True)\n",
        "  utils.save_image(output_img, output_name)\n",
        "  \n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Q_lF5IbRnl"
      },
      "source": [
        "#testset super resolution\n",
        "from glob import glob\n",
        "\n",
        "img_pathes = glob('/gdrive/MyDrive/Kinship Recognition Starter/test/' + \"*.jpg\")\n",
        "\n",
        "for img_path in img_pathes:\n",
        "  img = utils.read_cv2_img(img_path)\n",
        "  output_img = sr_forward(img)\n",
        "\n",
        "  output_name = img_path.replace('/gdrive/MyDrive/Kinship Recognition Starter/','')\n",
        "  os.makedirs(os.path.dirname(output_name), exist_ok=True)\n",
        "  utils.save_image(output_img, output_name)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}